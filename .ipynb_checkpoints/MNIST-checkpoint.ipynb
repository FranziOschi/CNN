{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franzi/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as k\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #everytime loading data won't be so easy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the data\n",
    "#sample = X_train.iloc[10, :]\n",
    "#sample = sample.reshape([28,28])\n",
    "#plt.imshow(sample, cmap='gray')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "#Reshape the training and test set\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#Padding the images by 2 pixels since in the paper input images were 32x32\n",
    "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "#Standardization\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "X_train = (X_train - mean_px)/(std_px)\n",
    "\n",
    "#One-hot encoding the labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_train[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "#this assumes our data format\n",
    "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n",
    "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "#if k.image_data_format() == 'channels_first':\n",
    "#    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "#    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "#    input_shape = (1, img_rows, img_cols)\n",
    "#else:\n",
    "#    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "#    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "#    input_shape = (img_rows, img_cols, 1)\n",
    "##more reshaping\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#print('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reshape the training and test set\n",
    "#X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "#X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Padding the images by 2 pixels since in the paper input images were 32x32\n",
    "#X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "#X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set number of categories\n",
    "#num_category = 10\n",
    "## convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# #Layer 1\n",
    "# #Conv Layer 1\n",
    "# model.add(Conv2D(filters = 6, \n",
    "#                  kernel_size = 5, \n",
    "#                  strides = 1, \n",
    "#                  activation = 'relu', \n",
    "#                  input_shape = (32,32,1)))\n",
    "# #Pooling layer 1\n",
    "# model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "# #Layer 2\n",
    "# #Conv Layer 2\n",
    "# model.add(Conv2D(filters = 16, \n",
    "#                  kernel_size = 5,\n",
    "#                  strides = 1,\n",
    "#                  activation = 'relu',\n",
    "#                  input_shape = (14,14,6)))\n",
    "# #Pooling Layer 2\n",
    "# model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "# #Flatten\n",
    "# model.add(Flatten())\n",
    "# #Layer 3\n",
    "# #Fully connected layer 1\n",
    "# model.add(Dense(units = 120, activation = 'relu'))\n",
    "# #Layer 4\n",
    "# #Fully connected layer 2\n",
    "# model.add(Dense(units = 84, activation = 'relu'))\n",
    "# #Layer 5\n",
    "# #Output Layer\n",
    "# model.add(Dense(units = 10, activation = 'softmax'))\n",
    "# # model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# # model.fit(X_train ,Y_train, steps_per_epoch = 10, epochs = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model building\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(1, kernel_size = (1,1), input_shape=input_shape, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation='tanh', input_shape = (32,32,1)))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size= 2, strides = 2))\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = 5, strides = 1, activation='tanh', input_shape = (14,14,6)))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size= 2, strides = 2))\n",
    "\n",
    "model.add(Conv2D(filters = 120, kernel_size = 5, strides = 1, activation='tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(units = 120, activation='tanh'))\n",
    "\n",
    "model.add(Dense(units = 84, activation='tanh'))\n",
    "\n",
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# num_epoch = 10\n",
    "# #model training\n",
    "# model_log = model.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=num_epoch,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test, Y_test))\n",
    "\n",
    "model.fit(X_train ,Y_train, steps_per_epoch = 1, epochs = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model building\n",
    "model = Sequential()\n",
    "#convolutional layer with rectified linear unit activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "#fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#one more dropout for convergence' sake :) \n",
    "model.add(Dropout(0.5))\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(num_category, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n",
    "#categorical ce since we have multiple classes (10) \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " 9728/60000 [===>..........................] - ETA: 2:40 - loss: 0.7189 - acc: 0.7725"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fdc9ed424731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/franzi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epoch = 10\n",
    "#model training\n",
    "model_log = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
